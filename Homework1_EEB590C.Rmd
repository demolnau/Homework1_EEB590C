---
title: "Homework 1 - EEB590C"
author: "Devin Molnau, Holly Loper, Elizabeth McMurchie "
date: "February 18, 2021"
output: pdf_document
---

```{r setup, include=FALSE}
library(knitr)
knitr::opts_chunk$set(echo = TRUE)
#install.packages("formatR")
opts_chunk$set(tidy.opts=list(width.cutoff=60),tidy=TRUE)
```

# EEB590C -Homework 1
## Homework 1: Lectures 1-4
This assignment is due prior to class in week 6. You are to self-select and work in groups: 2-3 in a group. For the assignment below submit one R-script. Annotations via comments are highly encouraged. The script should run!

### Assignment Instructions:

1: Select some form of linear model containing a single dependent variable (continuous) and at least 1 independent variable. Next, simulate two datasets: the first with no relationship between X & Y, and the second with some positive association between X & Y. Perform 100 simulations under each condition. Run the linear models on all datasets to confirm that on average, the patterns for condition 1 (no relationship) and condition 2 (some relationship) are met. (HINT: this requires determining an appropriate summary measure extracted from the linear model).

2: Devise a permutation procedure to evaluate the above linear model. Write code for this permutation procedure. Next, devise a SECOND implementation of the same permutation procedure (ie, code the procedure in a different manner). For a single dataset compare the two implementations for their computational performance. Summarize your findings via comments in the code (e.g., which approach was faster? Which components of the slower approach could be improved, etc.).

### Homework Breakdown:

Select some form of linear model containing a single dependent variable (continuous) and at least 1 independent variable. 


```{r}
#TODO
#DO WE NEED TO DECLARE A LINEAR MODEL HERE? SHOULD WE REMOVE THIS BREAK? wHAT IS CONSIDERED A LINEAR MODEL? 
```


Next, simulate two datasets: the first with no relationship between X & Y, and the second with some positive association between X & Y.
```{r}

#data set with no relationship between x & Y
set.seed(2) 
x1<-rnorm(100, mean = 0, sd = 0.3)
set.seed(3)
y1<-rnorm(100, mean = 3, sd = 2) #this could be pulled from any distribution (ie poisson, uniform...)
plot(x1,y1)

#TODO ADD LABELS AND TITLE
```

```{r}
#data set with positive association between x & Y
#install.packages("mvtnorm")
library(mvtnorm) 
corr.val <- .9
pos_cor_data <- rmvnorm(n=100,mean=c(0,0),sigma=matrix(c(1,corr.val,corr.val,1),2,2)) 
cor(pos_cor_data)

plot(pos_cor_data)
```

Perform 100 simulations under each condition.
```{r}
#TODO
#DOES THIS MEAN RESAMPLING OR DOES THIS MEAN INSTEAD OF 500 datapoints in each, there should be only 100?
#MAKE DATAFRAME OF 100 of 100
#FILL THE DATAFRAME ROW BY ROW WITH LIST OF 100


#load in libraries
#Random Uncorrelated Data List
uncor_data <- list()
sum_slopes_uncor_data <- 0

for (i in 1:100) {
  tmp <- list(rnorm(100, mean = 0, sd = 0.3)) #generate 100 uncorrelated points
  name <- paste('simulatation ', i, sep='') #make name for indexing later
  uncor_data[[name]] <- tmp # add simulation to list
  
  tmp_model <- lm(1:100 ~ tmp[[1]]) #make linear model 
  uncor_data[[name]][["linear_model"]] <- tmp_model #add linear model to list 
  
  uncor_data[[name]][["summary"]] <- summary(tmp_model) #summarize the fit of the linear model
  
  uncor_data[[name]][["anova"]] <- anova(tmp_model) #get model term tests
  
  sum_slopes_uncor_data <- sum_slopes_uncor_data + uncor_data[[name]][["linear_model"]][["coefficients"]][["tmp[[1]]"]]
}

#unlisted <- unlist(uncor_data[["simulatation 1"]])

#ununlisted <- unlist(unlisted)

#sum_slope_uncor_data_new <- lapply(uncor_data[[]][["linear_model"]][["coefficients"]][["tmp[[1]]"]], FUN = sum)

#sum_slope_uncor_data <- tapply(unlist(uncor_data[[]]), unlisted[["linear_model.coefficients.tmp[[1]]"]], lengths(uncor_data[[]])), FUN = sum)

#Random Correlated Data List
cor_data <- list()
corr.val <- 0.9
sum_slopes_cor_data <- 0

for (i in 1:100) {
  
  tmp <- list(rmvnorm(100, mean=c(0,0), sigma=matrix(c(1,corr.val,corr.val,1), 2, 2)))#generate 100 correlated points
  
  name <- paste('simulatation ', i, sep='') #make name for indexing later
  cor_data[[name]] <- tmp # add simulation to list
  
  tmp_model <- lm(tmp[[1]][,1] ~ tmp[[1]][,2]) #make linear model 
  cor_data[[name]][["linear_model"]] <- tmp_model #add linear model to list 
  
  cor_data[[name]][["summary"]] <- summary(tmp_model) #summarize the fit of the linear model
  
  cor_data[[name]][["anova"]] <- anova(tmp_model) #get model term tests
  
  sum_slopes_cor_data <- sum_slopes_cor_data + cor_data[[name]][["linear_model"]][["coefficients"]][["tmp[[1]][, 2]"]]
}


```

Run the linear models on all datasets to confirm that on average, the patterns for condition 1 (no relationship) and condition 2 (some relationship) are met. (HINT: this requires determining an appropriate summary measure extracted from the linear model).
```{r}
#model 1 - uncorrelated
lm(y1~x1)
model1<-lm(y1~x1)
summary(model1)	#pvalue of =  0.1593 --> 0.1593 > 0.05 significance threshold

#APPLY STATEMENT ON EACH LIST Of 100 ELEMENTS
```
 The pvalue of 0.1593 indicating that there is no significant linear relationship between x1 and y1 of model1. 

```{r}
#model 2 - positively correlated model

lm(pos_cor_data[,2]~pos_cor_data[,1])
model2<-lm(pos_cor_data[,2]~pos_cor_data[,1])
summary(model2)	

#APPLY STATEMENT ON EACH LIST Of 100 ELEMENTS
```
There is a significant linear relationship between x and y for the positively correlated model (model2) with a p value of 2.2e-16.
#### Question 2: 

 Devise a permutation procedure to evaluate the above linear model. Write code for this permutation procedure.
```{r}
#install.packages("RRPP")
library(RRPP)
ourdata<-rrpp.data.frame(pos_cor_data[,2], pos_cor_data[,1])
model3<-lm.rrpp(pos_cor_data[,2]~pos_cor_data[,1], print.progress = FALSE, data = ourdata)
anova(model3)

```

 Next, devise a SECOND implementation of the same permutation procedure (ie, code the procedure in a different manner). For a single dataset compare the two implementations for their computational performance.

```{r}
F.obs<-anova(model2)$F[[1]]  #Find Test value and save
permute<-1999
F.rand.vec<-array(NA,(permute+1))
F.rand.vec[permute+1]<-F.obs
 Y = pos_cor_data[,2]
 X1 = pos_cor_data[,1]
for(i in 1:permute){
  ###Shuffle Data
	y.rand<-sample(Y)	#Resample vector 
	F.rand.vec[i]<-anova(lm(y.rand~X1))$F[[1]]  
}  
F.obs
P.Ftest<-rank(F.rand.vec[permute+1])/(permute+1)
P.Ftest
####Plot
hist(F.rand.vec,40,freq=T,col="gray")
segments(F.obs, 0, F.obs, 50)  ##Plot Observed value
```

 
Summarize your findings via comments in the code (e.g., which approach was faster? Which components of the slower approach could be improved, etc.).